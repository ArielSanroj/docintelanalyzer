"""
Aplicaci√≥n Streamlit mejorada con sistema RAG-Anything.
Integra capacidades multimodales, contextuales y de grafo de conocimiento.
"""

import streamlit as st
import logging
import os
from pathlib import Path
import tempfile
import json

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configurar p√°gina
st.set_page_config(
    page_title="RAG-Anything Enhanced",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="expanded"
)

def initialize_rag_system():
    """Inicializa el sistema RAG-Anything."""
    if 'rag_system' not in st.session_state:
        try:
            from rag_anything_integration import RAGAnythingSystem
            
            st.session_state.rag_system = RAGAnythingSystem(
                embedding_model="all-MiniLM-L6-v2",
                vlm_model="nvidia/llama-3.2-vision-instruct",
                enable_vision=True,
                enable_context_awareness=True,
                enable_knowledge_graph=True
            )
            st.session_state.rag_initialized = True
            logger.info("Sistema RAG-Anything inicializado")
        except Exception as e:
            st.error(f"Error inicializando sistema RAG: {e}")
            st.session_state.rag_initialized = False
    else:
        st.session_state.rag_initialized = True

def main():
    """Funci√≥n principal de la aplicaci√≥n."""
    
    # T√≠tulo principal
    st.title("üöÄ RAG-Anything Enhanced")
    st.markdown("Sistema RAG Multimodal Avanzado con Capacidades de Visi√≥n, Contexto y Grafo de Conocimiento")
    
    # Inicializar sistema
    initialize_rag_system()
    
    if not st.session_state.rag_initialized:
        st.error("No se pudo inicializar el sistema RAG. Verifica las dependencias.")
        return
    
    # Sidebar para configuraci√≥n
    with st.sidebar:
        st.header("‚öôÔ∏è Configuraci√≥n")
        
        # Configuraci√≥n de capacidades
        st.subheader("Capacidades del Sistema")
        use_vision = st.checkbox("üëÅÔ∏è An√°lisis Visual", value=True, help="Habilitar an√°lisis de im√°genes y gr√°ficos")
        use_context = st.checkbox("üß† Procesamiento Contextual", value=True, help="Habilitar an√°lisis contextual avanzado")
        use_kg = st.checkbox("üîó Grafo de Conocimiento", value=True, help="Habilitar construcci√≥n de grafo de conocimiento")
        
        # Configuraci√≥n de recuperaci√≥n
        st.subheader("Par√°metros de Recuperaci√≥n")
        top_k = st.slider("N√∫mero de chunks a recuperar", 1, 10, 5)
        min_confidence = st.slider("Confianza m√≠nima", 0.0, 1.0, 0.3, 0.1)
        
        # Mostrar estad√≠sticas del sistema
        if st.session_state.rag_system.multimodal_rag.multimodal_chunks:
            st.subheader("üìä Estad√≠sticas del Documento")
            stats = st.session_state.rag_system.get_document_analysis()
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Chunks Totales", stats['document_stats']['total_chunks'])
                st.metric("Entidades", stats.get('knowledge_graph', {}).get('total_entities', 0))
            
            with col2:
                content_types = stats['document_stats']['content_types']
                st.metric("Tipos de Contenido", len(content_types))
                for content_type, count in content_types.items():
                    st.caption(f"{content_type}: {count}")
    
    # Pesta√±as principales
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üìÑ Documentos", 
        "üîç Consultas", 
        "üß† Grafo de Conocimiento", 
        "üìä An√°lisis", 
        "‚öôÔ∏è Configuraci√≥n"
    ])
    
    with tab1:
        document_processing_tab()
    
    with tab2:
        query_processing_tab(top_k, use_vision, use_context, use_kg)
    
    with tab3:
        knowledge_graph_tab()
    
    with tab4:
        analysis_tab()
    
    with tab5:
        configuration_tab()

def document_processing_tab():
    """Pesta√±a de procesamiento de documentos."""
    st.header("üìÑ Procesamiento de Documentos")
    
    # Opciones de carga
    upload_option = st.radio(
        "Selecciona m√©todo de carga:",
        ["Subir archivo", "Usar archivo de ejemplo", "Pegar texto"]
    )
    
    if upload_option == "Subir archivo":
        uploaded_file = st.file_uploader(
            "Selecciona un documento",
            type=['pdf', 'docx', 'pptx', 'xlsx', 'png', 'jpg', 'jpeg', 'gif', 'bmp', 'txt'],
            help="Formatos soportados: PDF, DOCX, PPTX, XLSX, im√°genes, TXT"
        )
        
        if uploaded_file is not None:
            # Guardar archivo temporalmente
            with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_path = tmp_file.name
            
            try:
                with st.spinner("Procesando documento..."):
                    st.session_state.rag_system.process_document(tmp_path)
                
                st.success("‚úÖ Documento procesado exitosamente!")
                
                # Mostrar estad√≠sticas
                stats = st.session_state.rag_system.get_document_analysis()
                display_document_stats(stats)
                
            except Exception as e:
                st.error(f"Error procesando documento: {e}")
            finally:
                # Limpiar archivo temporal
                os.unlink(tmp_path)
    
    elif upload_option == "Usar archivo de ejemplo":
        if st.button("Cargar documento de ejemplo"):
            sample_content = """
            # Informe de Proyecto de Investigaci√≥n
            
            ## Resumen Ejecutivo
            Este proyecto de investigaci√≥n se desarroll√≥ entre enero y diciembre de 2024, 
            bajo la direcci√≥n del Dr. Mar√≠a Gonz√°lez en la Universidad de Barcelona.
            
            ## Objetivos
            Los objetivos principales incluyen:
            1. Desarrollar un sistema de an√°lisis multimodal
            2. Implementar capacidades de visi√≥n artificial
            3. Crear un grafo de conocimiento integrado
            
            ## Metodolog√≠a
            La metodolog√≠a empleada combina t√©cnicas de:
            - Procesamiento de lenguaje natural
            - Visi√≥n por computadora
            - Aprendizaje autom√°tico
            
            ## Resultados
            Los resultados muestran una mejora del 25% en la precisi√≥n del sistema.
            
            ## Conclusiones
            El sistema desarrollado demuestra capacidades avanzadas de procesamiento multimodal.
            """
            
            try:
                with st.spinner("Procesando documento de ejemplo..."):
                    st.session_state.rag_system.process_document("sample_document.txt", sample_content)
                
                st.success("‚úÖ Documento de ejemplo procesado!")
                display_document_stats(st.session_state.rag_system.get_document_analysis())
                
            except Exception as e:
                st.error(f"Error procesando ejemplo: {e}")
    
    elif upload_option == "Pegar texto":
        text_content = st.text_area(
            "Pega el contenido del documento aqu√≠:",
            height=300,
            help="Pega el texto que quieres analizar"
        )
        
        if st.button("Procesar texto") and text_content.strip():
            try:
                with st.spinner("Procesando texto..."):
                    st.session_state.rag_system.process_document("text_input.txt", text_content)
                
                st.success("‚úÖ Texto procesado exitosamente!")
                display_document_stats(st.session_state.rag_system.get_document_analysis())
                
            except Exception as e:
                st.error(f"Error procesando texto: {e}")

def query_processing_tab(top_k, use_vision, use_context, use_kg):
    """Pesta√±a de procesamiento de consultas."""
    st.header("üîç Consultas Inteligentes")
    
    if not st.session_state.rag_system.multimodal_rag.multimodal_chunks:
        st.warning("‚ö†Ô∏è No hay documento cargado. Ve a la pesta√±a 'Documentos' para cargar uno.")
        return
    
    # Consulta del usuario
    query = st.text_input(
        "Haz tu consulta:",
        placeholder="Ej: ¬øCu√°les son los objetivos del proyecto?",
        help="Puedes hacer preguntas sobre el contenido del documento"
    )
    
    # Botones de consultas de ejemplo
    st.subheader("üí° Consultas de Ejemplo")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üìã Resumen general"):
            query = "¬øDe qu√© trata este documento?"
    
    with col2:
        if st.button("üéØ Objetivos"):
            query = "¬øCu√°les son los objetivos principales?"
    
    with col3:
        if st.button("üìä Resultados"):
            query = "¬øCu√°les fueron los resultados obtenidos?"
    
    # Procesar consulta
    if query:
        try:
            with st.spinner("Procesando consulta..."):
                response = st.session_state.rag_system.query_document(
                    query=query,
                    top_k=top_k,
                    use_context_awareness=use_context,
                    use_visual_analysis=use_vision,
                    use_knowledge_graph=use_kg
                )
            
            # Mostrar respuesta
            st.subheader("üí¨ Respuesta")
            st.write(response.answer)
            
            # Mostrar informaci√≥n adicional
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Confianza", f"{response.confidence_score:.3f}")
            with col2:
                st.metric("Chunks Relevantes", len(response.relevant_chunks))
            with col3:
                st.metric("An√°lisis Visual", "‚úÖ" if response.visual_analysis else "‚ùå")
            
            # Mostrar chunks relevantes
            if response.relevant_chunks:
                with st.expander("üìÑ Chunks Relevantes"):
                    for i, chunk in enumerate(response.relevant_chunks):
                        st.write(f"**Chunk {i+1}** ({chunk.content_type}):")
                        st.write(chunk.content[:500] + "..." if len(chunk.content) > 500 else chunk.content)
                        st.divider()
            
            # Mostrar an√°lisis contextual
            if response.contextual_analysis:
                with st.expander("üß† An√°lisis Contextual"):
                    context_summary = st.session_state.rag_system.context_processor.generate_contextual_summary(
                        response.contextual_analysis
                    )
                    st.write(context_summary)
            
            # Mostrar insights del grafo de conocimiento
            if response.knowledge_graph_insights:
                with st.expander("üîó Insights del Grafo de Conocimiento"):
                    insights = response.knowledge_graph_insights
                    if insights['relevant_entities']:
                        st.write("**Entidades Relevantes:**")
                        for entity in insights['relevant_entities']:
                            st.write(f"- {entity['name']} ({entity['type']}) - Confianza: {entity['confidence']:.3f}")
                    
                    if insights['entity_relationships']:
                        st.write("**Relaciones Identificadas:**")
                        for rel in insights['entity_relationships']:
                            st.write(f"- {rel['source']} ‚Üí {rel['target']} ({rel['relation_type']})")
            
        except Exception as e:
            st.error(f"Error procesando consulta: {e}")

def knowledge_graph_tab():
    """Pesta√±a del grafo de conocimiento."""
    st.header("üß† Grafo de Conocimiento")
    
    if not st.session_state.rag_system.knowledge_graph_system or not st.session_state.rag_system.knowledge_graph_system.knowledge_graph.entities:
        st.warning("‚ö†Ô∏è No hay grafo de conocimiento disponible. Procesa un documento primero.")
        return
    
    # Estad√≠sticas del grafo
    kg_stats = st.session_state.rag_system.knowledge_graph_system.get_entity_statistics()
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Entidades", kg_stats['total_entities'])
    with col2:
        st.metric("Relaciones", kg_stats['total_relations'])
    with col3:
        st.metric("Componentes", kg_stats['connected_components'])
    with col4:
        st.metric("Densidad", f"{kg_stats['graph_density']:.3f}")
    
    # Tipos de entidades
    st.subheader("üìä Tipos de Entidades")
    entity_types = kg_stats['entity_types']
    for entity_type, count in entity_types.items():
        st.write(f"**{entity_type.title()}**: {count}")
    
    # B√∫squeda de entidades
    st.subheader("üîç Explorar Entidades")
    entity_search = st.text_input("Buscar entidad:", placeholder="Ej: Universidad de Barcelona")
    
    if entity_search:
        # Buscar entidades relacionadas
        related_entities = st.session_state.rag_system.knowledge_graph_system.find_related_entities(
            entity_search, max_depth=2
        )
        
        if related_entities:
            st.write("**Entidades Relacionadas:**")
            for entity in related_entities:
                st.write(f"- {entity['entity_name']} ({entity['entity_type']}) - Profundidad: {entity['depth']}")
        else:
            st.write("No se encontraron entidades relacionadas.")
    
    # Exportar grafo
    st.subheader("üíæ Exportar Grafo")
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("Exportar JSON"):
            kg_json = st.session_state.rag_system.export_knowledge_graph("json")
            if kg_json:
                st.download_button(
                    "Descargar JSON",
                    kg_json,
                    "knowledge_graph.json",
                    "application/json"
                )
    
    with col2:
        if st.button("Generar Visualizaci√≥n"):
            graph_viz = st.session_state.rag_system.visualize_knowledge_graph(max_nodes=30)
            if graph_viz:
                st.image(graph_viz, caption="Visualizaci√≥n del Grafo de Conocimiento")
            else:
                st.warning("No se pudo generar la visualizaci√≥n. Instala matplotlib para habilitar esta funci√≥n.")

def analysis_tab():
    """Pesta√±a de an√°lisis."""
    st.header("üìä An√°lisis del Sistema")
    
    if not st.session_state.rag_system.multimodal_rag.multimodal_chunks:
        st.warning("‚ö†Ô∏è No hay documento cargado.")
        return
    
    # An√°lisis del documento
    analysis = st.session_state.rag_system.get_document_analysis()
    
    # Estad√≠sticas generales
    st.subheader("üìà Estad√≠sticas Generales")
    doc_stats = analysis['document_stats']
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric("Chunks Totales", doc_stats['total_chunks'])
        st.metric("Caracteres Totales", doc_stats['total_characters'])
    with col2:
        st.metric("Palabras Totales", doc_stats['total_words'])
        st.metric("Longitud Promedio", f"{doc_stats['avg_chunk_length']:.0f}")
    
    # Tipos de contenido
    st.subheader("üìã Distribuci√≥n de Contenido")
    content_types = doc_stats['content_types']
    
    if content_types:
        import plotly.express as px
        import pandas as pd
        
        df = pd.DataFrame(list(content_types.items()), columns=['Tipo', 'Cantidad'])
        fig = px.pie(df, values='Cantidad', names='Tipo', title="Distribuci√≥n de Tipos de Contenido")
        st.plotly_chart(fig, use_container_width=True)
    
    # Capacidades del sistema
    st.subheader("‚öôÔ∏è Capacidades del Sistema")
    capabilities = analysis['system_capabilities']
    
    for capability, enabled in capabilities.items():
        if isinstance(enabled, bool):
            st.write(f"**{capability}**: {'‚úÖ' if enabled else '‚ùå'}")
        else:
            st.write(f"**{capability}**: {enabled}")
    
    # Estad√≠sticas de procesamiento
    if 'processing_stats' in analysis:
        st.subheader("üîß Estad√≠sticas de Procesamiento")
        proc_stats = analysis['processing_stats']
        
        for key, value in proc_stats.items():
            if isinstance(value, dict):
                st.write(f"**{key}**:")
                for sub_key, sub_value in value.items():
                    st.write(f"  - {sub_key}: {sub_value}")
            else:
                st.write(f"**{key}**: {value}")

def configuration_tab():
    """Pesta√±a de configuraci√≥n."""
    st.header("‚öôÔ∏è Configuraci√≥n del Sistema")
    
    # Informaci√≥n del sistema
    st.subheader("‚ÑπÔ∏è Informaci√≥n del Sistema")
    
    if st.session_state.rag_initialized:
        capabilities = st.session_state.rag_system.get_system_capabilities()
        
        st.write("**Modelos Configurados:**")
        st.write(f"- Embedding: {capabilities['embedding_model']}")
        if capabilities['vlm_model']:
            st.write(f"- VLM: {capabilities['vlm_model']}")
        
        st.write("**Capacidades Habilitadas:**")
        for capability, enabled in capabilities.items():
            if isinstance(enabled, bool):
                st.write(f"- {capability}: {'‚úÖ' if enabled else '‚ùå'}")
    
    # Configuraci√≥n avanzada
    st.subheader("üîß Configuraci√≥n Avanzada")
    
    if st.button("üîÑ Reiniciar Sistema"):
        st.session_state.rag_system.reset_system()
        st.success("Sistema reiniciado exitosamente!")
    
    if st.button("üßπ Limpiar Memoria"):
        if 'rag_system' in st.session_state:
            del st.session_state.rag_system
        st.session_state.rag_initialized = False
        st.success("Memoria limpiada!")
    
    # Informaci√≥n de dependencias
    st.subheader("üì¶ Dependencias")
    st.write("Para instalar todas las dependencias necesarias:")
    st.code("pip install -r requirements_rag_anything.txt", language="bash")
    
    # Enlaces √∫tiles
    st.subheader("üîó Enlaces √ötiles")
    st.write("- [Documentaci√≥n RAG-Anything](https://github.com/HKUDS/RAG-Anything)")
    st.write("- [LangChain Documentation](https://python.langchain.com/)")
    st.write("- [Sentence Transformers](https://www.sbert.net/)")

def display_document_stats(stats):
    """Muestra estad√≠sticas del documento."""
    st.subheader("üìä Estad√≠sticas del Documento")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Chunks Totales", stats['total_chunks'])
        st.metric("Caracteres", stats['total_characters'])
    
    with col2:
        st.metric("Palabras", stats['total_words'])
        st.metric("Longitud Promedio", f"{stats['avg_chunk_length']:.0f}")
    
    with col3:
        st.metric("Embeddings", "‚úÖ" if stats['has_embeddings'] else "‚ùå")
        st.metric("Visi√≥n", "‚úÖ" if stats['vision_enabled'] else "‚ùå")
    
    # Tipos de contenido
    if 'content_types' in stats and stats['content_types']:
        st.write("**Tipos de Contenido:**")
        for content_type, count in stats['content_types'].items():
            st.write(f"- {content_type}: {count}")

if __name__ == "__main__":
    main()